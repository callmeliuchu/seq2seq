{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "318eaf9a-8b81-4742-8954-42ba371aeda5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada3884-cb7f-4201-89e8-e0765f767ea3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2eed65c9-a646-40f3-a6a3-896064186fb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self,dim,output_size):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.Wx = nn.Linear(dim,dim)\n",
    "        self.Wh = nn.Linear(dim,dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.Wy = nn.Linear(dim,output_size)\n",
    "        \n",
    "    def hiddend_state(self):\n",
    "        return torch.zeros(1, self.dim)\n",
    "        \n",
    "    def forward(self,x,h):\n",
    "        h = self.sigmoid(self.Wx(x) + self.Wh(h))\n",
    "        logits = self.Wy(h)\n",
    "        return h,logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78cfa71f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5825d586",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = 'WMT-Chinese-to-English-Machine-Translation-newstest/damo_mt_testsets_zh2en_news_wmt18.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c46d35bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d6031234",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "679f6b54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chs = df['0'].values\n",
    "ens = df['1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7605b0e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['声明补充说，沃伦的同事都深感震惊，并且希望他能够投案自首。', '不光改变硬件，软件也要跟上',\n",
       "       '“这不是我们习以为常的、可以称之为典型的谋杀事件。”', ...,\n",
       "       '在被唐纳德·特朗普总统任命之前，普鲁特是俄克拉何马州总检察长，长期以来反对环境法规的严格化。',\n",
       "       '在功能手机时代，手机的基本功能就是打电话、发短信、简单的备忘录，各种手机在功能上差距是不大的。',\n",
       "       '11月份全国热点城市房价趋稳，其中京沪深止涨，未来部分城市房价水平将继续回落。'], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "348125f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"The statement added that Warren's colleagues were shocked and want him to turn himself in.\",\n",
       "       'We should not only change the hardware, but the software must also keep up.',\n",
       "       '\"\\'This isn\\'t the type of murder that we\\'ve become used to and can call typical.\\'',\n",
       "       ...,\n",
       "       \"Pruitt, who was Oklahoma's state attorney general prior to his appointment by President Donald Trump, has long served as a reliable opponent of stricter environmental regulations.\",\n",
       "       'In a feature phone era, the basic functions of a mobile phone would be making a call, sending short text messages, and simple memos. The difference in the functions among mobile phones is quite small.',\n",
       "       'Residential property prices in popular cities nationwide stabilized in November. In particular, prices stopped rising in Beijing, Shanghai and Shenzhen. Going forward, the level of residential property prices in some cities will continue to decline.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a82db0ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self,sentences):\n",
    "        self.chars = set()\n",
    "        for sentence in sentences:\n",
    "            self.chars.update(set(sentence))\n",
    "        self.chars = list(self.chars)\n",
    "        self.bos = '<bos>'\n",
    "        self.eos = '<eos>'\n",
    "        self.chars.append(self.bos)\n",
    "        self.chars.append(self.eos)\n",
    "        self.encode = {c:i for i,c in enumerate(self.chars)}\n",
    "        self.decode = {i:c for i,c in enumerate(self.chars)}\n",
    "        self.vocab_size = len(self.encode)\n",
    "    \n",
    "    def to_ids(self,text):\n",
    "        return [self.encode[t] for t in text]\n",
    "    \n",
    "    def to_tokens(self,ids):\n",
    "        return [self.decode[_id] for _id in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7073a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ch_tokenizer = Tokenizer(chs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb89b569",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "en_tokenizer = Tokenizer(ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38800353",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ch_tokenizer.to_ids('声明补充说')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c594f30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "en_tokenizer.to_tokens(en_tokenizer.to_ids('The statement'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c60db5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef7e45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d7526",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "26308e22-c272-4e0a-b294-249e3475a659",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self,sentences):\n",
    "        self.chars = set()\n",
    "        for sentence in sentences:\n",
    "            self.chars.update(set(sentence))\n",
    "        self.chars = list(self.chars)\n",
    "        self.bos = '<bos>'\n",
    "        self.eos = '<eos>'\n",
    "        self.chars.append(self.bos)\n",
    "        self.chars.append(self.eos)\n",
    "        self.encode = {c:i for i,c in enumerate(self.chars)}\n",
    "        self.decode = {i:c for i,c in enumerate(self.chars)}\n",
    "        self.bos_index = self.encode[self.bos]\n",
    "        self.eos_index = self.encode[self.eos]\n",
    "        self.vocab_size = len(self.decode)\n",
    "    \n",
    "    def to_ids(self,text):\n",
    "        return [self.encode[t] for t in text]\n",
    "    \n",
    "    def to_tokens(self,ids):\n",
    "        return [self.decode[_id] for _id in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "98ae1b4f-e988-496e-8a76-90c813546252",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ch_tokenizer = Tokenizer(chs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "dc4fd3ca-5462-44d5-8638-16e635b0b250",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "en_tokenizer = Tokenizer(ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "798022fe-bcd1-411e-b832-9526369c7449",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1909, 396, 1710, 139, 2877]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_tokenizer.to_ids('声明补充说')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "52749356-5fea-4e62-83d4-f40570beeba7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'h', 'e', ' ', 's', 't', 'a', 't', 'e', 'm', 'e', 'n', 't']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tokenizer.to_tokens(en_tokenizer.to_ids('The statement'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8341492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6bc999a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self,dim,input_size,output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = RNN(dim,input_size)   \n",
    "        self.decoder = RNN(dim,output_size)   \n",
    "        self.input_embedding = nn.Embedding(input_size,dim)\n",
    "        self.output_embedding = nn.Embedding(output_size,dim)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def _forward(self,model,embedding,x,h):\n",
    "        h_seq = []\n",
    "        logits_seq = []\n",
    "        for xi in x:\n",
    "            xi = embedding(xi)\n",
    "            h,logits = model(xi,h)\n",
    "            h_seq.append(h)\n",
    "            logits_seq.append(logits)\n",
    "        h_seq = torch.cat(h_seq)\n",
    "        logits_seq = torch.cat(logits_seq)\n",
    "        return h_seq,logits_seq\n",
    "    \n",
    "    def encode(self,x):\n",
    "        h_seq,logits_seq = self._forward(self.encoder,self.input_embedding,x,self.encoder.hiddend_state())\n",
    "        return h_seq[-1].unsqueeze(0),logits_seq[-1]\n",
    "    \n",
    "    def decode(self,x,h):\n",
    "        h_seq,logits_seq = self._forward(self.decoder,self.output_embedding,x,h)\n",
    "        return h_seq,logits_seq\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        h,logits = self.encode(x)\n",
    "        y_input = y[:-1]\n",
    "        y_target = y[1:]\n",
    "        h_seq,logits_seq = self.decode(y_input,h)\n",
    "        loss = self.criterion(logits_seq,y_target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e3f2ecc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8b1579f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "78593656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_tokens(chs,ens,length=64):\n",
    "    indexs = list(range(len(chs)))\n",
    "    random.shuffle(indexs)\n",
    "    indexs = indexs[:64]\n",
    "    ch_tokens = [torch.LongTensor(ch_tokenizer.to_ids(chs[i])) for i in indexs]\n",
    "    en_tokens = [torch.LongTensor([en_tokenizer.bos_index]+en_tokenizer.to_ids(ens[i])+[en_tokenizer.eos_index]) for i in indexs]\n",
    "    return ch_tokens,en_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c020f455-1335-4244-af0a-b891591a4ffa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_x_y(tokens,seq_len):\n",
    "    i = random.randint(0,len(tokens)-seq_len-2)\n",
    "    seq = tokens[i:i+seq_len+1]\n",
    "    x = seq[:-1]\n",
    "    y = seq[1:]\n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe67ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fa6b8937-113f-4b86-960c-18193b6a56b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(dim,ch_tokenizer.vocab_size,en_tokenizer.vocab_size)\n",
    "optimizer = Adam(model.parameters(),lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7fec9702-fb55-4dcd-8966-f8d27039f2e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9531, grad_fn=<DivBackward0>)\n",
      "tensor(2.0128, grad_fn=<DivBackward0>)\n",
      "tensor(1.9718, grad_fn=<DivBackward0>)\n",
      "tensor(2.0313, grad_fn=<DivBackward0>)\n",
      "tensor(2.0086, grad_fn=<DivBackward0>)\n",
      "tensor(1.9663, grad_fn=<DivBackward0>)\n",
      "tensor(1.9844, grad_fn=<DivBackward0>)\n",
      "tensor(1.9719, grad_fn=<DivBackward0>)\n",
      "tensor(1.9349, grad_fn=<DivBackward0>)\n",
      "tensor(1.9897, grad_fn=<DivBackward0>)\n",
      "tensor(1.9703, grad_fn=<DivBackward0>)\n",
      "tensor(1.9948, grad_fn=<DivBackward0>)\n",
      "tensor(1.9552, grad_fn=<DivBackward0>)\n",
      "tensor(1.9794, grad_fn=<DivBackward0>)\n",
      "tensor(1.9674, grad_fn=<DivBackward0>)\n",
      "tensor(1.9696, grad_fn=<DivBackward0>)\n",
      "tensor(1.9698, grad_fn=<DivBackward0>)\n",
      "tensor(1.9706, grad_fn=<DivBackward0>)\n",
      "tensor(1.9608, grad_fn=<DivBackward0>)\n",
      "tensor(1.9649, grad_fn=<DivBackward0>)\n",
      "tensor(1.9818, grad_fn=<DivBackward0>)\n",
      "tensor(1.9339, grad_fn=<DivBackward0>)\n",
      "tensor(1.9488, grad_fn=<DivBackward0>)\n",
      "tensor(1.9628, grad_fn=<DivBackward0>)\n",
      "tensor(1.9528, grad_fn=<DivBackward0>)\n",
      "tensor(1.9384, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[213], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(loss)\n\u001B[1;32m     12\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 13\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m nn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     15\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/llama_hw/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    count = 0\n",
    "    loss = 0\n",
    "    ch_tokens,en_tokens = get_random_tokens(chs,ens,length=64)\n",
    "    for xi,yi in zip(ch_tokens,en_tokens):\n",
    "        lossi = model(xi,yi)\n",
    "        loss += lossi\n",
    "        count += 1\n",
    "    loss = loss / count\n",
    "    if epoch % 100 == 0:\n",
    "        print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b973203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,x):\n",
    "    x = torch.LongTensor(ch_tokenizer.to_ids(x))\n",
    "    h,logits = model.encode(x)\n",
    "    start = torch.LongTensor([en_tokenizer.bos_index])\n",
    "    for _ in range(100):\n",
    "        h_seq,logits_seq = model.decode(start,h)\n",
    "        logits = logits_seq[-1]\n",
    "        indexs = logits.argmax(dim=-1)\n",
    "        if indexs.item() == en_tokenizer.eos_index:\n",
    "            print('end')\n",
    "            break\n",
    "        indexs = indexs.unsqueeze(0)\n",
    "        start = torch.cat((start,indexs),dim=-1)\n",
    "    print(''.join(en_tokenizer.to_tokens(xi.item() for xi in start)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4e99fdd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>and the starting the starting the starting the starting the starting the starting the starting the s\n"
     ]
    }
   ],
   "source": [
    "predict(model,'手机的基本功能就是打电话')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4e518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ddbc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0c088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1dfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "81a3879c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ou should consider getting a taste of research as an undergradua'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(id2char[xi.item()] for xi in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c05c8eb8-d48b-489f-a6bb-e7068f026a6c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nrwhould bomsider iot ing t Phnt rsf teaearch i  a dander ram rt'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(id2char[xi.item()] for xi in logits.argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a42c37-35d4-4636-bbf5-af9882ad4478",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd37e99-bcc3-46ad-8174-1729964f72cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515a76b-7d8b-406b-9aa7-535a71b168ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7c5d6-a9ff-45b2-841e-25b41ab4d93a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ad462-02fc-41cd-a905-fcdc53b8651a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llama_hw)",
   "language": "python",
   "name": "llama_hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}